# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Обзор проекта

Это **система реального времени для перевода речи в речь**, которая объединяет детекцию голосовой активности (VAD), распознавание речи Faster-Whisper и нейронный машинный перевод CTranslate2 в потоковом конвейере:

```
Аудио вход → NemoVAD → Faster-Whisper → CTranslate2 → Выход перевода
```

## Архитектура

### Основные компоненты

- **`runTransWin.py`** - Главный оркестратор, управляющий циклом обработки в реальном времени
- **`lib/ctrans_manager.py`** - Менеджер переводов CTranslate2 с динамической загрузкой моделей
- **`lib/nemo_vad/`** - Реализация VAD на C++ с Python-биндингами для сегментации аудио
- **`lib/nemo_tokenizer/`** - Токенизатор на C++ с Python-биндингами для эффективной обработки текста

### Конвейер обработки

Система выполняет непрерывный цикл:
1. Захватывает аудио с использованием VAD для обнаружения речевых сегментов
2. Транскрибирует аудио моделями Faster-Whisper
3. Фильтрует галлюцинации с помощью языко-специфичного сопоставления паттернов
4. Переводит текст моделями CTranslate2 NLLB
5. Выводит результаты с управлением GPU-памятью и кешированием моделей

### Паттерн гибридной архитектуры

- **Python-слой**: Высокоуровневая оркестрация, управление моделями, конфигурация
- **C++ расширения**: Критичная по производительности обработка аудио и токенизация
- **Предобученные модели**: Использует экосистему HuggingFace (Whisper, NLLB)

## Команды разработки

### Установка
```bash
# Установка для NVIDIA GPU
Install.bat

# Установка для AMD/CPU
install_amd.bat

# Ручная установка
pip install -r requirements.txt        # NVIDIA CUDA 12.8
pip install -r requirements_amd.txt    # AMD ROCm/CPU
```

### Запуск
```bash
# Базовый перевод в реальном времени
python runTransWin.py

# С конкретными параметрами
python runTransWin.py -m large -s eng_Latn -t kor_Hang -p "nvidia float16"

# Использование bat-файла запуска
start_realtrans.bat
```

### Ключевые параметры
- **`-m/--model_size`**: Размер модели Whisper (small, medium, turbo, large, huge)
- **`-s/--source_lang`**: Исходный язык (например, eng_Latn, kor_Hang)
- **`-t/--target_lang`**: Целевой язык
- **`-p/--proc`**: Метод обработки (nvidia float16/32, amd float16/32, CPU)
- **`-d/--device`**: Аудио устройство (speaker, mic)

### Управление во время выполнения
Система использует **`pymsg.json`** для команд во время работы:
```json
{
  "source_lang": "eng_Latn",
  "target_lang": "kor_Hang", 
  "rec_enable": true,
  "trans_enable": true,
  "exit": false
}
```

## Файлы конфигурации

- **`whisper_lang_map.json`** - Сопоставления языковых кодов между Whisper и NLLB
- **`hallucination_filter.json`** - Фильтры для каждого языка от артефактов транскрипции Whisper
- **`config.json`** - Настройки UI и приложения

## Управление моделями

`ctrans_manager.py` обрабатывает:
- **Автоматические загрузки**: Модели загружаются с HuggingFace при первом использовании
- **Поддержка множественных моделей**: Универсальные модели (small→huge) и специализированные (en2ko, ko2en)
- **Динамическое переключение**: Изменяет модели перевода в зависимости от языковых пар
- **Оптимизация памяти**: Очистка GPU-памяти и кеширование моделей

Размеры моделей варьируются от 600МБ (small) до 6.7ГБ (huge).

## C++ расширения

Два критичных C++ компонента с Python-биндингами:
- **`nemo_vad_core.pyd`** - Детекция голосовой активности в реальном времени
- **`nemo_tokenizer_core.pyd`** - Высокопроизводительная токенизация SentencePiece

Они обрабатывают критичные по производительности операции обработки аудио и токенизации текста.

## Системные требования

- **GPU**: NVIDIA CUDA (предпочтительно) или AMD ROCm (доступен CPU fallback)
- **Память**: 2-8ГБ в зависимости от выбранного размера модели
- **Аудио**: Возможность захвата системного аудио для входа через динамики/микрофон

## Заметки по разработке

- **Python 3.12** - целевая среда выполнения (указано в bat-файлах)
- **Нет формальной инфраструктуры тестирования** - тестирование в настоящее время ручное/ad-hoc
- **Производительность в реальном времени**: Система оптимизирована для потокового перевода с низкой задержкой
- **Поддержка нескольких GPU**: Автоматическое обнаружение GPU с fallback на CPU
- **Восстановление после ошибок**: Graceful обработка сбоев загрузки моделей и очистка ресурсов